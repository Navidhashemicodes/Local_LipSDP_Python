{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Other Methods\n",
    "In this tutorial, we'll describe how to incorporate other Lipschitz estimation techniques into our codebase. For each method, we try to use the official codebase attached to the papers. We simply built an interface on top of each of these to be more amenable to our system. The methods we consider are:\n",
    "* **CLEVER**: Uses randomly sampled points and extremal value theory to generate an heuristic Lipschitz estimate([github](https://github.com/IBM/CLEVER-Robustness-Score)). \n",
    "* **FastLip**: Uses the hyperbox and boolean hyperbox abstract domains to efficiently generate an upper bound to the Lipschitz constant ([github](https://github.com/huanzhang12/CertifiedReLURobustness)).\n",
    "* **LipLP**: The naive linear programming relaxation to LipMIP\n",
    "* **LipSDP**: Uses incremental quadratic constraints and semidefinite programming to generate a global upper bound of Lipschitz constants in the $\\ell_2$ setting ([github](https://github.com/arobey1/LipSDP)).\n",
    "* **SeqLip**: Frames Lipschitz estimation as a combinatorial optimization problem and uses greedy methods to generate a heuristic Lipschitz estimate ([github](https://github.com/avirmaux/lipEstimation)).\n",
    "* **RandomLB**: Randomly samples points and takes their maximal gradient norm. This is like CLEVER, but doesn't use the extremal value theory step, and thereby provides a certifiable lower bound.\n",
    "* **NaiveUB**: Multiplies the operator norm of each component of a ReLU network together to yield an extremely loose upper bound.\n",
    "\n",
    "Note that LipSDP uses the Mosek plugin for matlab to solve SDP's. Follow the instructions in their github to install these dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# import matlab.engine\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch \n",
    "from pprint import pprint \n",
    "import numpy as np\n",
    "\n",
    "import utilities as utils\n",
    "from relu_nets import ReLUNet\n",
    "from hyperbox import Hyperbox \n",
    "from lipMIP import LipMIP\n",
    "from other_methods import CLEVER, FastLip, LipLP, NaiveUB, RandomLB\n",
    "import experiment as exp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Individual Methods\n",
    "The interface to run each method is identical, and all inherit a generic `OtherResult` class (except for LipMIP). We demonstrate how to run each method here.\n",
    "\n",
    "Many methods have variants and hyperparameters that can be tuned. We incorporate these as kwargs and can tune them in our repository, but leave them mostly as default from their original codebases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic network example \n",
    "\n",
    "test_network = torch.load('2by2comparison.pt')\n",
    "test_network = ReLUNet([2, 100, 100, 2], manual_net = test_network)\n",
    "test_domain = Hyperbox.build_unit_hypercube(2)\n",
    "primal_norm = 'linf'\n",
    "c_vector = torch.Tensor([1, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: The `Experiment` class\n",
    "As a convenient and flexible shorthand to evaluate lipschitz constants of various networks under various settings, we built the `Experiment` class which is very handy for performing common operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_class = [CLEVER, FastLip, LipLP, NaiveUB, RandomLB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- build experiment object \n",
    "basic_exp = exp.Experiment(eval_class, network=test_network, c_vector=c_vector, primal_norm=primal_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'CLEVER': 0.05958084017038345, 'FastLip': 0.05958084, 'LipLP': 0.05958084017038345, 'NaiveUB': 35.692245, 'RandomLB': tensor(0.0596)}, {'CLEVER': 0.15852293372154236, 'FastLip': 5.5080576, 'LipLP': 5.395470239583757, 'NaiveUB': 35.692245, 'RandomLB': tensor(0.1247)}, {'CLEVER': 0.2652759552001953, 'FastLip': 7.424658, 'LipLP': 7.309843351300828, 'NaiveUB': 35.692245, 'RandomLB': tensor(0.2649)}, {'CLEVER': 0.3093941807746887, 'FastLip': 9.269087, 'LipLP': 9.122953795347009, 'NaiveUB': 35.692245, 'RandomLB': tensor(0.2899)}, {'CLEVER': 0.41606879234313965, 'FastLip': 10.033554, 'LipLP': 9.90973699257325, 'NaiveUB': 35.692245, 'RandomLB': tensor(0.3963)}, {'CLEVER': 0.41606879234313965, 'FastLip': 11.18173, 'LipLP': 11.03768231066567, 'NaiveUB': 35.692245, 'RandomLB': tensor(0.3963)}, {'CLEVER': 0.41606879234313965, 'FastLip': 12.409562, 'LipLP': 12.253464338085777, 'NaiveUB': 35.692245, 'RandomLB': tensor(0.4045)}, {'CLEVER': 0.41606879234313965, 'FastLip': 12.656469, 'LipLP': 12.52235987632194, 'NaiveUB': 35.692245, 'RandomLB': tensor(0.3963)}, {'CLEVER': 0.41606879234313965, 'FastLip': 12.840517, 'LipLP': 12.725491573504907, 'NaiveUB': 35.692245, 'RandomLB': tensor(0.4097)}, {'CLEVER': 0.41606879234313965, 'FastLip': 12.963369, 'LipLP': 12.865026503563787, 'NaiveUB': 35.692245, 'RandomLB': tensor(0.4161)}]\n"
     ]
    }
   ],
   "source": [
    "#  evaluating local lipschitz constants across [-r, +r]^d where r is a parameter taken to be large\n",
    "T=[]\n",
    "epsis=np.linspace(0.001, 1, num=10)\n",
    "for epsilon in epsis:\n",
    "    large_r_result = basic_exp.do_large_radius_eval(epsilon)\n",
    "    T.append(large_r_result.values())\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_class = [LipMIP]\n",
    "basic_exp = exp.Experiment(eval_class, network=test_network, c_vector=c_vector, primal_norm=primal_norm)\n",
    "T=[]\n",
    "epsis=np.linspace(0.001, 1, num=10)\n",
    "for epsilon in epsis:\n",
    "    large_r_result = basic_exp.do_large_radius_eval(epsilon)\n",
    "    T.append(large_r_result.values())\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
